{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Реализовать самостоятельно логистическую регрессию\n",
    "Обучить ее методом градиентного спуска\n",
    "Методом nesterov momentum\n",
    "Методом rmsprop\n",
    "В качестве dataset’а взять Iris, оставив 2 класса:\n",
    "Iris Versicolor\n",
    "Iris Virginica\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "from sklearn.datasets import load_iris\n",
    "import tensorflow as tf\n",
    "\n",
    "N = 100\n",
    "X = np.random.uniform(low=0, high=100, size=N)\n",
    "Y = 2*X + 1 + np.random.normal(scale=5, size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Применим метод градиентного спуска для случаного уравнения. Наша задача - получить наиболее оптимальные коэффециенты params\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.8150215743611149 -0.28372478288756975\n",
      "-1.8039091720835734 0.44742984331796043\n",
      "-1.7962700635340292 0.9493522826988267\n",
      "-1.7910152999352102 1.2939115442518956\n",
      "-1.7873973403659926 1.5304442233308464\n",
      "-1.784903013371097 1.6928188771214165\n",
      "-1.78318003730938 1.8042855729949054\n",
      "-1.7819865780854112 1.8808050036317088\n",
      "-1.7811566215704846 1.9333338560284623\n",
      "-1.7805762024824032 1.9693936702803347\n",
      "-1.7801670860007455 1.9941478288423138\n",
      "-1.7798755655316376 2.0111408874887684\n",
      "-1.7796647726038517 2.0228061107990976\n",
      "-1.7795093977707674 2.0308138848217228\n",
      "-1.7793920666182306 2.036310895196333\n",
      "-1.779300851968544 2.0400843180116595\n",
      "-1.7792275660597145 2.042674533449703\n",
      "-1.7791665881616587 2.0444525013824375\n",
      "-1.779114059758861 2.0456728781262865\n",
      "-1.7790673320598338 2.0465104800007303\n"
     ]
    }
   ],
   "source": [
    "costs = []   # потери \n",
    "params = []\n",
    "preds = []\n",
    "params = np.random.normal(size=(2,))  # случайно заданная строка 2-х параметров (исходные точки)\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    predictions = params[0] + params[1] * X\n",
    "    preds.append(predictions)\n",
    "\n",
    "    cost = np.sum(np.square(predictions - Y)) / (2 * len(predictions))\n",
    "    costs.append(cost)\n",
    "    \n",
    "    params[0] -= LEARNING_RATE * np.sum(predictions - Y) / len(predictions)\n",
    "    params[1] -= LEARNING_RATE * np.sum((predictions - Y) * X) / len(predictions)  \n",
    "    print(params[0], params[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kwargs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-921e7e8f22ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m tf.keras.optimizers.RMSprop(\n\u001b[0;32m      4\u001b[0m     \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-07\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcentered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     name='RMSprop', **kwargs) \n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# метод nesterov momentum в TensorFlow (https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/MomentumOptimizer?hl=ru)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kwargs' is not defined"
     ]
    }
   ],
   "source": [
    "# метод rmsprop в TensorFlow (https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop?hl=ru)\n",
    "\n",
    "tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
    "    name='RMSprop', **kwargs) \n",
    "\n",
    "# метод nesterov momentum в TensorFlow (https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/MomentumOptimizer?hl=ru)\n",
    "tf.compat.v1.train.MomentumOptimizer(\n",
    "    learning_rate, momentum, use_locking=False, name='Momentum',\n",
    "    use_nesterov=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2.92649172, -1.36006538, -2.11183437, -0.65850995]),\n",
       " -0.49200241340550505)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Реализуем код градиентного спуска в явном виде для датасета Iris\n",
    "\n",
    "X,y = load_iris(return_X_y=True)\n",
    "filter = y != 2              # накладываем фильтр - только 2 признака\n",
    "X = X[filter]\n",
    "y = y[filter]\n",
    "\n",
    "COEFS = np.random.randn(5)   # генерируем случайные коэффициенты\n",
    "\n",
    "def predict_proba(coefs, x):\n",
    "  # формула логистической регрессии:\n",
    "  return 1. / (1. + np.exp( -(x.dot(coefs[:4]) + coefs[-1]) ) ) \n",
    "\n",
    "# теперь на основе модели предсказываем класс (но модель пока не обучена: \n",
    "# это сделаем градиентным спуском чуть позже)\n",
    "def predict_class(coefs, x):\n",
    "    probas = predict_proba(coefs, x)\n",
    "    return (probas > 0.5).astype(np.float)\n",
    "\n",
    "# явно прописываем функцию потерь на основе ее формулы\n",
    "def bce_loss(coefs, x, y):\n",
    "    probas = predict_proba(coefs, x)\n",
    "    filter_ones = y == 1\n",
    "    loss = -1. * (np.sum(np.log(probas[filter_ones])) + np.sum(np.log(1. - probas[~filter_ones]))) / len(y)\n",
    "    return loss\n",
    "\n",
    "# расчет градиента:\n",
    "# он зависит от двух сущностей: от модели и функции потерь\n",
    "def grad(coefs, x, y):\n",
    "    probas = predict_proba(coefs, x)\n",
    "    delta = probas - y\n",
    "    modified_x = x.T * delta\n",
    "    deltas = np.mean(modified_x, axis=1)\n",
    "    return deltas, np.mean(delta)\n",
    "\n",
    "# обучение модели методом градиентного спуска\n",
    "def learn_sgd(coefs, x, y, num_epochs=20, learning_rate=0.0001):\n",
    "    losses = []                                               # solutions = list()\n",
    "    for e in range(num_epochs):\n",
    "        grad_coefs, grad_bias = grad(coefs, x, y)             # gradient = derivative(projected[0], projected[1])\n",
    "        coefs[:-1] = coefs[:-1] - learning_rate * grad_coefs\n",
    "        coefs[-1] = coefs[-1] - learning_rate * grad_bias\n",
    "        loss = bce_loss(coefs, x, y)\n",
    "        losses.append(loss)\n",
    "    return losses, coefs\n",
    "\n",
    "grad(COEFS, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-82d559df4b4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mlearn_nesterov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCOEFS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-82d559df4b4f>\u001b[0m in \u001b[0;36mlearn_nesterov\u001b[1;34m(coefs, x, y, num_epochs, momentum, learning_rate)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoefs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mv_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mv_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgr_coefs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mcoefs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mv_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbce_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# Реализуем метод Нестеров моментум для того же самого датасета. Эвристика заключается в добавлении импульса (momentum) \n",
    "# и расчете градиента для следующей точки графика. Оказавшись в одном локальном минимуме, \n",
    "# мы сможем перескочиться через следующую \"горку\", чтобы увидеть там локальный минимум бОльшей глубины. \n",
    "# Вот общая формула: \n",
    "#     Nesterov Momentum v_t = momentum* v_t{t-1} + learning_rate*grad(coefs - momentum v_t{t-1}), \n",
    "#     где coefs = coefs{t-1} - v_t. \n",
    "# Видим, что скорость в точке t соотносится со скоростью в точке t-1.\n",
    "\n",
    "def learn_nesterov(coefs, x, y, num_epochs=20, momentum=0.9, learning_rate=0.0001):\n",
    "    v_t = [0 for _ in range(len(coefs))]\n",
    "    losses =[]\n",
    "    for i in range(num_epochs):\n",
    "        pr_coefs  = [coefs[i] - momentum*v_t[i] for i in range(len(coefs))]\n",
    "        gr_coefs = grad(pr_coefs, x, y)\n",
    "        for i in range(len(coefs)):\n",
    "            v_t[i]=momentum*v_t[i] + learning_rate*gr_coefs[i]\n",
    "            coefs[i] -= v_t[i]\n",
    "        losses.append(bce_loss(x, y, coefs))\n",
    "    return losses, coefs\n",
    "\n",
    "learn_nesterov(COEFS, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь займемся методом RMSprop (применим его для того же самого датасета Iris)\n",
    "\n",
    "def learn_RMSprop(coefs, x, y, num_epochs=20, momentum=0.9, learning_rate=0.0001):\n",
    "    e = 10**(-8)\n",
    "    S = [0 for _ in range(len(coefs))]\n",
    "    losses =[]\n",
    "    for it in range(num_epochs):\n",
    "        gr_coefs = grad(x, y, coefs)\n",
    "        gr_coefs_2 = [x**2 for x in gr_coefs]\n",
    "        for i in range(len(coefs)):\n",
    "            S[i]=momentum*S[i] + (1-momentum)*gr_coefs_2[i]\n",
    "            coefs[i] = coefs[i]-learning_rate* (gr_coefs[i]/(math.sqrt(S[i])+e))  \n",
    "        losses.append(bce_loss(coefs, x, y))\n",
    "    return losses, coefs\n",
    "\n",
    "learn_RMSprop(COEFS, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
